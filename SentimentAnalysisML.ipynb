{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24dba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977e552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tourist_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654900eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5294\n",
       "negative    2846\n",
       "neutral      935\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfaeed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after i was going there on vacation and i was ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaning is often not taken care of</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corruption of the staff is on the rise if you ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice place to visit with lots of greenery entr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i came back totally disappointed from the top ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews    labels\n",
       "0  after i was going there on vacation and i was ...  negative\n",
       "1                cleaning is often not taken care of  negative\n",
       "2  corruption of the staff is on the rise if you ...  negative\n",
       "3  nice place to visit with lots of greenery entr...  positive\n",
       "4  i came back totally disappointed from the top ...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9065a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       9075\n",
       "unique      8574\n",
       "top       boring\n",
       "freq          17\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d81a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9075 entries, 0 to 9074\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   class    9075 non-null   int64 \n",
      " 1   reviews  9075 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 141.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfbef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe to store results\n",
    "df_Results = pd.DataFrame(columns=['Model','Accuracy','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc766be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to plot confusion matrix\n",
    "def Plot_confusion_matrix(y_test, y_pred):\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  print(cm)\n",
    "  plt.clf()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ade4942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : 7260\n",
      "X_test  : 1815\n",
      "y_train : 7260\n",
      "y_test  : 1815\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset \n",
    "x = df['reviews']\n",
    "y = df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 225)\n",
    "\n",
    "print('X_train :', len(X_train))\n",
    "print('X_test  :', len(X_test))\n",
    "print('y_train :', len(y_train))\n",
    "print('y_test  :', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "302a7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "X_train_tfidf = tvec.fit_transform(X_train)\n",
    "X_test_tfidf = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0863dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 562  149]\n",
      " [  54 1050]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       711\n",
      "           1       0.88      0.95      0.91      1104\n",
      "\n",
      "    accuracy                           0.89      1815\n",
      "   macro avg       0.89      0.87      0.88      1815\n",
      "weighted avg       0.89      0.89      0.89      1815\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall\n",
      "0  Logistic Regression  0.888154   0.896563  0.888154\n",
      "1  Logistic Regression  0.888154   0.896563  0.888154\n"
     ]
    }
   ],
   "source": [
    "#logistic Regression\n",
    "tvec = TfidfVectorizer()\n",
    "clf2 = LogisticRegression(solver = \"lbfgs\")\n",
    "\n",
    "model = Pipeline([('vectorizer',tvec),('classifier',clf2)])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "#predicting test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# finding Accuaracy \n",
    "accuracy_logistic = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "precision_logistic = metrics.precision_score(y_pred, y_test, average = 'weighted')\n",
    "recall_logistic = metrics.recall_score(y_pred, y_test, average = 'weighted')\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "Plot_confusion_matrix(y_test, y_pred)\n",
    "print(\"classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_Results = df_Results.append(pd.DataFrame({'Model': 'Logistic Regression','Accuracy': accuracy_logistic,'Precision': precision_logistic,'Recall': recall_logistic}, index=[0]),ignore_index= True)\n",
    "\n",
    "print(df_Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a01fa179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 562  149]\n",
      " [  54 1050]]\n"
     ]
    }
   ],
   "source": [
    "#print(\"Accuracy : \", accuracy_score(predictions, y_test))\n",
    "#print(\"Precision : \", precision_score(predictions, y_test, average = 'weighted'))\n",
    "#print(\"Recall : \", recall_score(predictions, y_test, average = 'weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8a3e386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini score: 0.790633608815427\n",
      "Confusion Matrix\n",
      "[[518 193]\n",
      " [187 917]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       711\n",
      "           1       0.83      0.83      0.83      1104\n",
      "\n",
      "    accuracy                           0.79      1815\n",
      "   macro avg       0.78      0.78      0.78      1815\n",
      "weighted avg       0.79      0.79      0.79      1815\n",
      "\n",
      "entropy score: 0.7994490358126721\n",
      "Confusion Matrix\n",
      "[[529 182]\n",
      " [182 922]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       711\n",
      "           1       0.84      0.84      0.84      1104\n",
      "\n",
      "    accuracy                           0.80      1815\n",
      "   macro avg       0.79      0.79      0.79      1815\n",
      "weighted avg       0.80      0.80      0.80      1815\n",
      "\n",
      "                              Model  Accuracy  Precision    Recall\n",
      "0               Logistic Regression  0.888154   0.896563  0.888154\n",
      "1               Logistic Regression  0.888154   0.896563  0.888154\n",
      "2     Tree Model with gini criteria  0.790634   0.790971  0.790634\n",
      "3  Tree Model with entropy criteria  0.799449   0.799449  0.799449\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Decision Tree model with 'gini' & 'entropy'\n",
    "criteria = ['gini', 'entropy'] \n",
    "scores = {} \n",
    "\n",
    "    \n",
    "for c in criteria: \n",
    "    dt = DecisionTreeClassifier(criterion = c, random_state=42) \n",
    "    model1 = Pipeline([('vectorizer',tvec),('classifier',dt)])\n",
    "    model1.fit(X_train, y_train)\n",
    "    y_pred = model1.predict(X_test)\n",
    "    test_score = model1.score(X_test, y_test)\n",
    "    accuracy_tree = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    precision_tree = metrics.precision_score(y_pred, y_test, average = 'weighted')\n",
    "    recall_tree = metrics.recall_score(y_pred, y_test, average = 'weighted')\n",
    "    print(c + \" score: {0}\" .format(test_score))\n",
    "    print(\"Confusion Matrix\")\n",
    "    Plot_confusion_matrix(y_test, y_pred)\n",
    "    print(\"classification Report\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    df_Results = df_Results.append(pd.DataFrame({'Model': 'Tree Model with {0} criteria'.format(c),'Accuracy': accuracy_tree,'Precision': precision_tree,'Recall': recall_tree}, index=[0]),ignore_index= True)\n",
    "print(df_Results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f19dfd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 526  185]\n",
      " [  56 1048]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81       711\n",
      "           1       0.85      0.95      0.90      1104\n",
      "\n",
      "    accuracy                           0.87      1815\n",
      "   macro avg       0.88      0.84      0.86      1815\n",
      "weighted avg       0.87      0.87      0.86      1815\n",
      "\n",
      "                              Model  Accuracy  Precision    Recall\n",
      "0               Logistic Regression  0.888154   0.896563  0.888154\n",
      "1               Logistic Regression  0.888154   0.896563  0.888154\n",
      "2     Tree Model with gini criteria  0.790634   0.790971  0.790634\n",
      "3  Tree Model with entropy criteria  0.799449   0.799449  0.799449\n",
      "4                     Random Forest  0.867218   0.882106  0.867218\n"
     ]
    }
   ],
   "source": [
    "#Random Forest model\n",
    "# Create the model with 100 trees\n",
    "RF_model = RandomForestClassifier(n_estimators=100, \n",
    "                            bootstrap = True,\n",
    "                            max_features = 'sqrt', random_state=42)\n",
    "model2 = Pipeline([('vectorizer',tvec),('classifier',RF_model)])\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "#predicting test set results\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# finding Accuaracy \n",
    "accuracy_rf = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "precision_rf = metrics.precision_score(y_pred, y_test, average = 'weighted')\n",
    "recall_rf = metrics.recall_score(y_pred, y_test, average = 'weighted')\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "Plot_confusion_matrix(y_test, y_pred)\n",
    "print(\"classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_Results = df_Results.append(pd.DataFrame({'Model': 'Random Forest','Accuracy': accuracy_rf,'Precision': precision_rf,'Recall': recall_rf}, index=[0]),ignore_index= True)\n",
    "\n",
    "print(df_Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd817ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "example = [\"The guided tour was fantastic. The tour guide was engaging and informative, and showed us a side of the city we wouldn't have seen on our own. I would highly recommend it.\"]\n",
    "\n",
    "result = model2.predict(example)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
